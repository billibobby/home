{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Analysis\n",
    "\n",
    "This notebook analyzes and visualizes the alpha-generating features created by the trading bot's feature engineering system.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Compare basic vs alpha features\n",
    "- Analyze feature distributions and correlations\n",
    "- Visualize time series patterns\n",
    "- Detect regime changes\n",
    "- Simulate feature importance\n",
    "- Performance benchmarks\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Run the cells in order:\n",
    "1. Setup and Imports (Cell 1)\n",
    "2. Load Configuration (Cell 2)\n",
    "3. Data Fetching (Cell 4)\n",
    "4. Feature Generation (Cells 6-7)\n",
    "5. Analysis cells (8-21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent.parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import trading bot modules\n",
    "from trading_bot.data.stock_fetcher import StockDataFetcher\n",
    "from trading_bot.data.feature_engineer import FeatureEngineer\n",
    "from trading_bot.data.alpha_features import AlphaFeatures\n",
    "from trading_bot.config_loader import Config\n",
    "\n",
    "# Set plotting style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Configuration\n",
    "config = Config()\n",
    "# Load config from file (will use default path or can specify custom path)\n",
    "config_path = project_root / 'config' / 'config.yaml'\n",
    "if config_path.exists():\n",
    "    try:\n",
    "        config.load_config(str(config_path))\n",
    "        print(f\"Configuration loaded from {config_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load config from {config_path}: {e}\")\n",
    "        print(\"Using default configuration\")\n",
    "else:\n",
    "    print(f\"Warning: Config file not found at {config_path}, using defaults\")\n",
    "\n",
    "# Create logger (mock for notebook)\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching\n",
    "\n",
    "Fetch historical stock data for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "symbol = 'AAPL'\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "fetcher = StockDataFetcher(config, logger)\n",
    "data = fetcher.fetch_historical_data(symbol, start_date, end_date, interval='1d')\n",
    "\n",
    "print(f\"Fetched {len(data)} rows of data for {symbol}\")\n",
    "print(f\"Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic vs Alpha Feature Generation\n",
    "\n",
    "Generate features using both basic and alpha feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature engineer (basic features)\n",
    "feature_engineer = FeatureEngineer(config, logger)\n",
    "\n",
    "# Generate basic features\n",
    "basic_features = feature_engineer.create_features(data.copy())\n",
    "print(f\"Basic features: {len(basic_features.columns)} columns\")\n",
    "print(f\"Basic feature names: {[col for col in basic_features.columns if col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable alpha features by modifying config\n",
    "# Create a mock config object that supports set() method\n",
    "class MockConfig:\n",
    "    def __init__(self, base_config):\n",
    "        self._config = base_config._config.copy()\n",
    "        self._defaults = base_config._defaults.copy()\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        \"\"\"Get config value using dot notation.\"\"\"\n",
    "        keys = key.split('.')\n",
    "        value = self._config\n",
    "        for k in keys:\n",
    "            if isinstance(value, dict) and k in value:\n",
    "                value = value[k]\n",
    "            else:\n",
    "                return default\n",
    "        return value\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        \"\"\"Set config value using dot notation.\"\"\"\n",
    "        keys = key.split('.')\n",
    "        config = self._config\n",
    "        for k in keys[:-1]:\n",
    "            if k not in config:\n",
    "                config[k] = {}\n",
    "            config = config[k]\n",
    "        config[keys[-1]] = value\n",
    "\n",
    "config_alpha = MockConfig(config)\n",
    "config_alpha.set('models.features.use_alpha_features', True)\n",
    "config_alpha.set('models.features.alpha_feature_groups', \n",
    "                ['microstructure', 'regime', 'momentum', 'volume', 'time_based'])\n",
    "\n",
    "# Create feature engineer with alpha features\n",
    "feature_engineer_alpha = FeatureEngineer(config_alpha, logger)\n",
    "\n",
    "# Generate features with alpha features\n",
    "alpha_features = feature_engineer_alpha.create_features(data.copy())\n",
    "print(f\"Alpha features: {len(alpha_features.columns)} columns\")\n",
    "\n",
    "# Get alpha feature names\n",
    "alpha_feature_names = [col for col in alpha_features.columns \n",
    "                      if col not in basic_features.columns and col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "print(f\"\\nAlpha feature names ({len(alpha_feature_names)}):\")\n",
    "print(alpha_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions\n",
    "\n",
    "Analyze the distribution of key features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features to visualize\n",
    "key_features = ['return_1d', 'spread_proxy', 'vwap', 'volatility_regime', \n",
    "                'trend_strength', 'z_score', 'momentum_10d', 'obv', 'relative_volume']\n",
    "\n",
    "# Filter to features that exist\n",
    "available_features = [f for f in key_features if f in alpha_features.columns]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(available_features[:9]):\n",
    "    if feature in alpha_features.columns:\n",
    "        ax = axes[i]\n",
    "        alpha_features[feature].dropna().hist(bins=50, ax=ax, alpha=0.7)\n",
    "        ax.set_title(f'{feature}')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.axvline(alpha_features[feature].mean(), color='r', linestyle='--', label='Mean')\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "alpha_features[available_features].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heatmap\n",
    "\n",
    "Visualize feature correlations to identify multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features for correlation\n",
    "numeric_features = alpha_features.select_dtypes(include=[np.number]).columns\n",
    "# Remove Date index if present\n",
    "numeric_features = [f for f in numeric_features if f != 'Date']\n",
    "\n",
    "# Calculate correlation matrix (sample if too many features)\n",
    "if len(numeric_features) > 30:\n",
    "    # Sample features for visualization\n",
    "    sample_features = numeric_features[:30]\n",
    "else:\n",
    "    sample_features = numeric_features\n",
    "\n",
    "corr_matrix = alpha_features[sample_features].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.8:\n",
    "            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))\n",
    "\n",
    "print(f\"\\nHighly correlated feature pairs (|correlation| > 0.8):\")\n",
    "for pair in high_corr_pairs[:10]:\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Plots\n",
    "\n",
    "Visualize feature evolution over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Date as index if not already\n",
    "if 'Date' in alpha_features.columns:\n",
    "    alpha_features_ts = alpha_features.set_index('Date')\n",
    "else:\n",
    "    alpha_features_ts = alpha_features.copy()\n",
    "\n",
    "# Plot key time series features\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "# Price and VWAP\n",
    "if 'Close' in alpha_features_ts.columns and 'vwap' in alpha_features_ts.columns:\n",
    "    axes[0].plot(alpha_features_ts.index, alpha_features_ts['Close'], label='Close', alpha=0.7)\n",
    "    axes[0].plot(alpha_features_ts.index, alpha_features_ts['vwap'], label='VWAP', alpha=0.7)\n",
    "    axes[0].set_title('Price vs VWAP')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend strength\n",
    "if 'trend_strength' in alpha_features_ts.columns:\n",
    "    axes[1].plot(alpha_features_ts.index, alpha_features_ts['trend_strength'], label='Trend Strength', color='green')\n",
    "    axes[1].axhline(0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_title('Trend Strength')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility regime\n",
    "if 'volatility_regime' in alpha_features_ts.columns:\n",
    "    axes[2].plot(alpha_features_ts.index, alpha_features_ts['volatility_regime'], label='Volatility Regime', color='orange')\n",
    "    axes[2].set_title('Volatility Regime (0=Low, 1=High)')\n",
    "    axes[2].set_ylim(-0.1, 1.1)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Momentum\n",
    "if 'momentum_10d' in alpha_features_ts.columns:\n",
    "    axes[3].plot(alpha_features_ts.index, alpha_features_ts['momentum_10d'], label='10-Day Momentum', color='purple')\n",
    "    axes[3].axhline(0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[3].set_title('Momentum')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection\n",
    "\n",
    "Analyze market regime changes using volatility and trend features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regime analysis\n",
    "if 'volatility_regime' in alpha_features_ts.columns and 'trend_strength' in alpha_features_ts.columns:\n",
    "    # Combine regime indicators\n",
    "    regime_df = pd.DataFrame({\n",
    "        'volatility': alpha_features_ts['volatility_regime'],\n",
    "        'trend': alpha_features_ts['trend_strength']\n",
    "    })\n",
    "    \n",
    "    # Create regime classification\n",
    "    regime_df['regime'] = 'Neutral'\n",
    "    regime_df.loc[(regime_df['volatility'] == 0) & (regime_df['trend'] > 0.05), 'regime'] = 'Low Vol + Uptrend'\n",
    "    regime_df.loc[(regime_df['volatility'] == 0) & (regime_df['trend'] < -0.05), 'regime'] = 'Low Vol + Downtrend'\n",
    "    regime_df.loc[(regime_df['volatility'] == 1) & (regime_df['trend'] > 0.05), 'regime'] = 'High Vol + Uptrend'\n",
    "    regime_df.loc[(regime_df['volatility'] == 1) & (regime_df['trend'] < -0.05), 'regime'] = 'High Vol + Downtrend'\n",
    "    \n",
    "    # Plot regime over time\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    # Price with regime overlay\n",
    "    if 'Close' in alpha_features_ts.columns:\n",
    "        axes[0].plot(alpha_features_ts.index, alpha_features_ts['Close'], label='Close Price', alpha=0.7)\n",
    "        \n",
    "        # Color code by regime\n",
    "        for regime_type in regime_df['regime'].unique():\n",
    "            regime_mask = regime_df['regime'] == regime_type\n",
    "            axes[0].scatter(alpha_features_ts.index[regime_mask], \n",
    "                           alpha_features_ts['Close'][regime_mask],\n",
    "                           label=regime_type, alpha=0.5, s=10)\n",
    "        \n",
    "        axes[0].set_title('Price with Regime Overlay')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Regime distribution\n",
    "    regime_counts = regime_df['regime'].value_counts()\n",
    "    axes[1].bar(regime_counts.index, regime_counts.values)\n",
    "    axes[1].set_title('Regime Distribution')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nRegime Distribution:\")\n",
    "    print(regime_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Feature Importance\n",
    "\n",
    "Simulate feature importance scores for visualization (requires trained model for actual importance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate feature importance (for demonstration)\n",
    "# In practice, this would come from a trained model\n",
    "feature_names = [col for col in alpha_features.columns \n",
    "                if col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "# Simulate importance scores (random for demonstration)\n",
    "np.random.seed(42)\n",
    "simulated_importance = np.random.exponential(0.1, len(feature_names))\n",
    "simulated_importance = simulated_importance / simulated_importance.sum()  # Normalize\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': simulated_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "top_features = importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Top 20 Feature Importance (Simulated)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features by Importance:\")\n",
    "print(top_features.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmarks\n",
    "\n",
    "Measure feature generation performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark feature generation\n",
    "test_data = data.copy()\n",
    "\n",
    "# Basic features\n",
    "start = time.time()\n",
    "basic_result = feature_engineer.create_features(test_data.copy())\n",
    "basic_time = time.time() - start\n",
    "\n",
    "# Alpha features\n",
    "start = time.time()\n",
    "alpha_result = feature_engineer_alpha.create_features(test_data.copy())\n",
    "alpha_time = time.time() - start\n",
    "\n",
    "# Benchmark results\n",
    "benchmark_results = pd.DataFrame({\n",
    "    'Method': ['Basic Features', 'Alpha Features'],\n",
    "    'Time (seconds)': [basic_time, alpha_time],\n",
    "    'Number of Features': [len(basic_result.columns), len(alpha_result.columns)],\n",
    "    'Time per Feature (ms)': [basic_time / len(basic_result.columns) * 1000, \n",
    "                               alpha_time / len(alpha_result.columns) * 1000]\n",
    "})\n",
    "\n",
    "print(\"Performance Benchmarks:\")\n",
    "print(benchmark_results)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].bar(benchmark_results['Method'], benchmark_results['Time (seconds)'])\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Feature Generation Time')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1].bar(benchmark_results['Method'], benchmark_results['Number of Features'])\n",
    "axes[1].set_ylabel('Number of Features')\n",
    "axes[1].set_title('Feature Count')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Generate summary statistics for all features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nSymbol: {symbol}\")\n",
    "print(f\"Date Range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "print(f\"Total Rows: {len(data)}\")\n",
    "\n",
    "print(f\"\\nBasic Features: {len(basic_features.columns)} columns\")\n",
    "print(f\"Alpha Features: {len(alpha_features.columns)} columns\")\n",
    "print(f\"Additional Features from Alpha: {len(alpha_features.columns) - len(basic_features.columns)}\")\n",
    "\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"  - Microstructure: {len([f for f in alpha_feature_names if any(x in f for x in ['spread', 'vwap', 'price_impact', 'order_flow', 'relative_volume'])])}\")\n",
    "print(f\"  - Regime: {len([f for f in alpha_feature_names if any(x in f for x in ['volatility_regime', 'trend_strength', 'z_score', 'hurst', 'adx'])])}\")\n",
    "print(f\"  - Momentum: {len([f for f in alpha_feature_names if 'momentum' in f or 'acceleration' in f or 'rsi' in f])}\")\n",
    "print(f\"  - Volume: {len([f for f in alpha_feature_names if any(x in f for x in ['obv', 'volume', 'price_volume'])])}\")\n",
    "print(f\"  - Time-based: {len([f for f in alpha_feature_names if any(x in f for x in ['day_of_week', 'hour', 'month', 'earnings'])])}\")\n",
    "\n",
    "print(f\"\\nMissing Values:\")\n",
    "missing_counts = alpha_features.isnull().sum()\n",
    "missing_features = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "if len(missing_features) > 0:\n",
    "    print(f\"  Features with missing values: {len(missing_features)}\")\n",
    "    print(f\"  Top 5:\")\n",
    "    for feature, count in missing_features.head(5).items():\n",
    "        pct = (count / len(alpha_features)) * 100\n",
    "        print(f\"    {feature}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"  No missing values!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
